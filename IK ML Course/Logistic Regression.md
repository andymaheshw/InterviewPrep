- Logistic regression is an extension of linear regression with the sigmoid function on top. 1/1+e^(-ax+b)
* P(y=1| x) = P(x) = aX + b
* log(P(X)/(1-P(X))) => gets us the coefficients in linear form
* log loss = y * log(pi) + (1-y) * log(1-p)
* recall = true positives/ (all positives) 
* precision = true positives/ trues
* F1 score = imbalanced class distribution. best f1 is 1
* sensitivity = true positive rate (recall)
* specificity = 1 - false positive rate
* ROC curve - ROC Raise TPR and lower false positive Rate
* AUC overall classifier performance
* 